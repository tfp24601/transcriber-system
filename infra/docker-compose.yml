services:
  # Web PWA frontend
  transcriber-web:
    build: ../web
    container_name: transcriber-web
    restart: unless-stopped
    ports:
      - "3010:80"
    networks:
      - transcriber_network
    environment:
      - NODE_ENV=production
    volumes:
      - ../web/nginx.conf:/etc/nginx/conf.d/default.conf:ro

  # Faster-Whisper ASR Gateway (OpenAI-compatible API)
  asr-gateway:
    image: fedirz/faster-whisper-server:latest
    container_name: transcriber-asr-gateway
    restart: unless-stopped
    ports:
      - "8000:8000"
    networks:
      - transcriber_network
    environment:
      - MODEL_NAME=large-v3  # Can be changed to medium.en for faster processing
      - DEVICE=cuda
      - COMPUTE_TYPE=float16
      - HOST=0.0.0.0
      - PORT=8000
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    volumes:
      - asr_models:/app/models
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # WhisperX worker for diarization and alignment
  whisperx-worker:
    image: jimapp/whisperx:latest
    container_name: transcriber-whisperx-worker
    restart: unless-stopped
    ports:
      - "8001:8000"
    networks:
      - transcriber_network
    environment:
      - WHISPERX_MODEL=large-v3
      - DEVICE=cuda
      - COMPUTE_TYPE=float16
      - HF_TOKEN=${HUGGINGFACE_TOKEN:-}  # Required for speaker diarization models
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    volumes:
      - whisperx_models:/root/.cache/huggingface
      - ../data:/data
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:8000/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s

  # Tusd resumable upload server (optional but recommended)
  tusd:
    image: tusproject/tusd:latest
    container_name: transcriber-tusd
    restart: unless-stopped
    ports:
      - "1080:1080"
    networks:
      - transcriber_network
    command: >
      -host=0.0.0.0
      -port=1080
      -upload-dir=/data/uploads
      -hooks-dir=/hooks
      -hooks-http=http://n8n:5678/webhook/tus-upload-complete
      -hooks-http-forward-headers=Authorization,CF-Access-Jwt-Assertion
      -max-size=10737418240
      -timeout=3600000
    volumes:
      - ../data/uploads:/data/uploads
      - ./tusd-hooks:/hooks:ro
    depends_on:
      - n8n

  # Redis for job queuing and status (reuse existing or create new)
  redis-transcriber:
    image: docker.io/valkey/valkey:8-alpine
    container_name: redis-transcriber
    restart: unless-stopped
    networks:
      - transcriber_network
    volumes:
      - redis_transcriber_data:/data
    command: valkey-server --save 30 1 --loglevel warning
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5

networks:
  transcriber_network:
    driver: bridge
  # Connect to your existing Sol network for n8n and postgres access
  external_network:
    external: true
    name: sol_default_network

volumes:
  asr_models:
    driver: local
  whisperx_models:
    driver: local
  redis_transcriber_data:
    driver: local